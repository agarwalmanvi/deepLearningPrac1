{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV0p4Vh8v0yd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b265a7d1-46bd-48f6-d885-9f696a8a8a41"
      },
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, AveragePooling2D, Input\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D\n",
        "from keras.layers.advanced_activations import LeakyReLU \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "\n",
        "np.random.seed(10)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8GTenY6w-px",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Kuzushiji MNIST\n",
        "from mlxtend.data import loadlocal_mnist\n",
        "X_train, y_train = loadlocal_mnist(\n",
        "        images_path='/content/train-images-idx3-ubyte', \n",
        "        labels_path='/content/train-labels-idx1-ubyte')\n",
        "\n",
        "X_test, y_test = loadlocal_mnist(\n",
        "        images_path='/content/t10k-images-idx3-ubyte', \n",
        "        labels_path='/content/t10k-labels-idx1-ubyte')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwc9QtK6xCsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train/=255\n",
        "X_test/=255\n",
        "\n",
        "number_of_classes = 10\n",
        "\n",
        "Y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, number_of_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRc_D0pJxJAM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 3\n",
        "depth = n * 6 + 2\n",
        "\n",
        "input_shape = X_train.shape[1:]\n",
        "\n",
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): ConvÂ 2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "  \n",
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = n\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            # commented this bcoz image is too small to downsample\n",
        "            #if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                #strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELVwhA-PxNTT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "8a258f15-aebe-4b77-8adb-087bd0d74e6b"
      },
      "source": [
        "model = resnet_v1(input_shape=input_shape, depth=depth)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLPRS4c5xP6n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1909
        },
        "outputId": "47bcb257-1b46-4a87-9747-ff5a115cd714"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=SGD(momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(X_train, Y_train, batch_size=128, epochs=50, verbose=1, validation_data=(X_test, Y_test))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 51s 851us/step - loss: 0.9122 - acc: 0.7826 - val_loss: 3.3635 - val_acc: 0.2194\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 46s 763us/step - loss: 0.4069 - acc: 0.9313 - val_loss: 5.9555 - val_acc: 0.2086\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 47s 778us/step - loss: 0.3228 - acc: 0.9542 - val_loss: 3.0054 - val_acc: 0.4439\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 47s 776us/step - loss: 0.2882 - acc: 0.9625 - val_loss: 3.4767 - val_acc: 0.4015\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 47s 778us/step - loss: 0.2634 - acc: 0.9675 - val_loss: 1.1674 - val_acc: 0.6802\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 47s 780us/step - loss: 0.2460 - acc: 0.9723 - val_loss: 1.5144 - val_acc: 0.5411\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 47s 779us/step - loss: 0.2332 - acc: 0.9748 - val_loss: 2.1582 - val_acc: 0.4930\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 47s 778us/step - loss: 0.2221 - acc: 0.9782 - val_loss: 3.4224 - val_acc: 0.4161\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 47s 777us/step - loss: 0.2127 - acc: 0.9798 - val_loss: 7.1033 - val_acc: 0.1340\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 47s 778us/step - loss: 0.2087 - acc: 0.9805 - val_loss: 2.5327 - val_acc: 0.4783\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 47s 776us/step - loss: 0.1997 - acc: 0.9816 - val_loss: 4.2693 - val_acc: 0.3785\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 47s 777us/step - loss: 0.1950 - acc: 0.9827 - val_loss: 6.3644 - val_acc: 0.2165\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 47s 777us/step - loss: 0.1871 - acc: 0.9850 - val_loss: 6.5570 - val_acc: 0.1835\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 47s 777us/step - loss: 0.1842 - acc: 0.9848 - val_loss: 2.2609 - val_acc: 0.4955\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 47s 777us/step - loss: 0.1785 - acc: 0.9862 - val_loss: 2.0583 - val_acc: 0.5115\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 47s 776us/step - loss: 0.1736 - acc: 0.9869 - val_loss: 1.7298 - val_acc: 0.5882\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 47s 780us/step - loss: 0.1705 - acc: 0.9878 - val_loss: 2.2245 - val_acc: 0.5040\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 47s 777us/step - loss: 0.1662 - acc: 0.9880 - val_loss: 4.5848 - val_acc: 0.3003\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 47s 779us/step - loss: 0.1610 - acc: 0.9891 - val_loss: 1.5058 - val_acc: 0.6367\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 47s 777us/step - loss: 0.1574 - acc: 0.9896 - val_loss: 1.9066 - val_acc: 0.5367\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 47s 777us/step - loss: 0.1558 - acc: 0.9893 - val_loss: 2.5149 - val_acc: 0.5043\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 47s 777us/step - loss: 0.1535 - acc: 0.9896 - val_loss: 1.6088 - val_acc: 0.5682\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 47s 777us/step - loss: 0.1508 - acc: 0.9900 - val_loss: 2.5663 - val_acc: 0.5536\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 47s 778us/step - loss: 0.1460 - acc: 0.9909 - val_loss: 1.5305 - val_acc: 0.6329\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 47s 777us/step - loss: 0.1428 - acc: 0.9914 - val_loss: 3.2824 - val_acc: 0.5060\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 47s 779us/step - loss: 0.1401 - acc: 0.9917 - val_loss: 5.2857 - val_acc: 0.1840\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 46s 775us/step - loss: 0.1361 - acc: 0.9929 - val_loss: 4.6917 - val_acc: 0.3433\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 46s 769us/step - loss: 0.1337 - acc: 0.9928 - val_loss: 1.1255 - val_acc: 0.7192\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 46s 771us/step - loss: 0.1317 - acc: 0.9928 - val_loss: 2.3329 - val_acc: 0.5195\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 47s 777us/step - loss: 0.1289 - acc: 0.9930 - val_loss: 3.6355 - val_acc: 0.4650\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 47s 778us/step - loss: 0.1263 - acc: 0.9937 - val_loss: 2.8269 - val_acc: 0.4900\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 47s 777us/step - loss: 0.1244 - acc: 0.9935 - val_loss: 6.8532 - val_acc: 0.1927\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 47s 778us/step - loss: 0.1227 - acc: 0.9938 - val_loss: 4.1256 - val_acc: 0.3967\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 47s 777us/step - loss: 0.1217 - acc: 0.9935 - val_loss: 2.3874 - val_acc: 0.5691\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 47s 776us/step - loss: 0.1180 - acc: 0.9940 - val_loss: 3.1478 - val_acc: 0.3623\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 47s 778us/step - loss: 0.1152 - acc: 0.9947 - val_loss: 2.0696 - val_acc: 0.5918\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 47s 776us/step - loss: 0.1115 - acc: 0.9957 - val_loss: 1.4438 - val_acc: 0.6325\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 47s 777us/step - loss: 0.1123 - acc: 0.9945 - val_loss: 4.1534 - val_acc: 0.3948\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 47s 778us/step - loss: 0.1093 - acc: 0.9954 - val_loss: 0.9128 - val_acc: 0.7975\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 47s 777us/step - loss: 0.1093 - acc: 0.9944 - val_loss: 4.3490 - val_acc: 0.4588\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 47s 777us/step - loss: 0.1082 - acc: 0.9946 - val_loss: 11.2671 - val_acc: 0.1000\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 47s 777us/step - loss: 0.1060 - acc: 0.9949 - val_loss: 2.0403 - val_acc: 0.5532\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 47s 777us/step - loss: 0.1029 - acc: 0.9956 - val_loss: 5.4653 - val_acc: 0.2672\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 47s 776us/step - loss: 0.1026 - acc: 0.9951 - val_loss: 2.3889 - val_acc: 0.4287\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 47s 778us/step - loss: 0.0989 - acc: 0.9961 - val_loss: 6.1576 - val_acc: 0.2835\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 47s 779us/step - loss: 0.0979 - acc: 0.9961 - val_loss: 2.1608 - val_acc: 0.5845\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 47s 776us/step - loss: 0.0969 - acc: 0.9954 - val_loss: 1.0828 - val_acc: 0.7642\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 47s 777us/step - loss: 0.0952 - acc: 0.9961 - val_loss: 4.8193 - val_acc: 0.3789\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 47s 776us/step - loss: 0.0944 - acc: 0.9959 - val_loss: 0.7141 - val_acc: 0.8327\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 47s 778us/step - loss: 0.0925 - acc: 0.9961 - val_loss: 5.6126 - val_acc: 0.3802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEp1JCJHxTqg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ed216ff2-686e-4f2a-ae17-953e9516e769"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 3s 303us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8nfxtLs82Kj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_history = history.history['loss']\n",
        "accuracy_history = history.history['acc']\n",
        "val_loss_history = history.history['val_loss']\n",
        "val_accuracy_history = history.history['val_acc']\n",
        "\n",
        "import csv\n",
        "\n",
        "with open('resnet-sigmoid.csv', \"w\") as outfile:\n",
        "    outfile.write(\"loss,accuracy,val_loss,val_acc\")\n",
        "    outfile.write(\"\\n\")\n",
        "    for ind in range(len(loss_history)):\n",
        "        outfile.write(str(loss_history[ind])+','+str(accuracy_history[ind])+','+str(val_loss_history[ind])+','+str(val_accuracy_history[ind]))\n",
        "        outfile.write(\"\\n\")\n",
        "        \n",
        "with open('resnet-sigmoid-modelevaluate.csv', \"w\") as outfile:\n",
        "    outfile.write(\"loss,\")\n",
        "    outfile.write(\"accuracy\")\n",
        "    outfile.write(\"\\n\")\n",
        "    outfile.write(str(score[0])+',')\n",
        "    outfile.write(str(score[1]))\n",
        "    outfile.write(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}